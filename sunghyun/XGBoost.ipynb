{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import  OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('./test.csv').drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('ì„ì‹  ì„±ê³µ ì—¬ë¶€', axis=1)\n",
    "y = train['ì„ì‹  ì„±ê³µ ì—¬ë¶€']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    \"ì‹œìˆ  ì‹œê¸° ì½”ë“œ\",\n",
    "    \"ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´\",\n",
    "    \"ì‹œìˆ  ìœ í˜•\",\n",
    "    \"íŠ¹ì • ì‹œìˆ  ìœ í˜•\",\n",
    "    \"ë°°ë€ ìê·¹ ì—¬ë¶€\",\n",
    "    \"ë°°ë€ ìœ ë„ ìœ í˜•\",\n",
    "    \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\",\n",
    "    \"ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€\",\n",
    "    \"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\",\n",
    "    \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• \",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\",\n",
    "    \"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "    \"ì´ ì‹œìˆ  íšŸìˆ˜\",\n",
    "    \"í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜\",\n",
    "    \"IVF ì‹œìˆ  íšŸìˆ˜\",\n",
    "    \"DI ì‹œìˆ  íšŸìˆ˜\",\n",
    "    \"ì´ ì„ì‹  íšŸìˆ˜\",\n",
    "    \"IVF ì„ì‹  íšŸìˆ˜\",\n",
    "    \"DI ì„ì‹  íšŸìˆ˜\",\n",
    "    \"ì´ ì¶œì‚° íšŸìˆ˜\",\n",
    "    \"IVF ì¶œì‚° íšŸìˆ˜\",\n",
    "    \"DI ì¶œì‚° íšŸìˆ˜\",\n",
    "    \"ë‚œì ì¶œì²˜\",\n",
    "    \"ì •ì ì¶œì²˜\",\n",
    "    \"ë‚œì ê¸°ì¦ì ë‚˜ì´\",\n",
    "    \"ì •ì ê¸°ì¦ì ë‚˜ì´\",\n",
    "    \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\n",
    "    \"ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\n",
    "    \"ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\n",
    "    \"ëŒ€ë¦¬ëª¨ ì—¬ë¶€\",\n",
    "    \"PGD ì‹œìˆ  ì—¬ë¶€\",\n",
    "    \"PGS ì‹œìˆ  ì—¬ë¶€\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype(str)\n",
    "    test[col] = test[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "X_train_encoded = X.copy()\n",
    "X_train_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "X_test_encoded = test.copy()\n",
    "X_test_encoded[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "    \"ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜\",\n",
    "    \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\",\n",
    "    \"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\",\n",
    "    \"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜\",\n",
    "    \"ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"í•´ë™ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"í•´ë™ ë‚œì ìˆ˜\",\n",
    "    \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\",\n",
    "    \"ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜\",\n",
    "    \"í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"ë‚œì ì±„ì·¨ ê²½ê³¼ì¼\",\n",
    "    \"ë‚œì í•´ë™ ê²½ê³¼ì¼\",\n",
    "    \"ë‚œì í˜¼í•© ê²½ê³¼ì¼\",\n",
    "    \"ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼\",\n",
    "    \"ë°°ì•„ í•´ë™ ê²½ê³¼ì¼\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ëŠ” Feature: {'í•´ë™ ë‚œì ìˆ˜_missing', 'IVF ì‹œìˆ  íšŸìˆ˜', 'ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€', 'ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜_missing', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜_missing', 'IVF ì„ì‹  íšŸìˆ˜', 'ì €ì¥ëœ ë°°ì•„ ìˆ˜_missing', 'IVF ì¶œì‚° íšŸìˆ˜', 'ëŒ€ë¦¬ëª¨ ì—¬ë¶€', 'ë°°ì•„ í•´ë™ ê²½ê³¼ì¼_missing', 'ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜_missing', 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜_missing', 'ë°°ë€ ìœ ë„ ìœ í˜•', 'ì´ì‹ëœ ë°°ì•„ ìˆ˜_missing', 'ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜_missing', 'ë‚œì ì±„ì·¨ ê²½ê³¼ì¼_missing', 'ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€', 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜', 'ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸', 'í•´ë™ëœ ë°°ì•„ ìˆ˜_missing', 'ì´ ìƒì„± ë°°ì•„ ìˆ˜_missing', 'ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜_missing', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜_log', 'íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜_missing', 'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜_missing', 'íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜', 'í˜¼í•©ëœ ë‚œì ìˆ˜_missing'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1ï¸âƒ£ ê²°ì¸¡ ì—¬ë¶€ Feature ì¶”ê°€\n",
    "for col in numeric_columns:\n",
    "    X_train_encoded[col + '_missing'] = X_train_encoded[col].isna().astype(int)\n",
    "    X_test_encoded[col + '_missing'] = X_test_encoded[col].isna().astype(int)\n",
    "\n",
    "# zero_imputer = SimpleImputer(strategy=\"constant\", fill_value=0)\n",
    "# X_train_encoded[numeric_columns] = zero_imputer.fit_transform(X_train_encoded[numeric_columns])\n",
    "# X_test_encoded[numeric_columns] = zero_imputer.transform(X_test_encoded[numeric_columns])\n",
    "\n",
    "from numpy import log1p\n",
    "# ğŸ”¹ ë¡œê·¸ ë³€í™˜ ì ìš© (Skewed Data Handling)\n",
    "skewed_cols = ['ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜', 'ì €ì¥ëœ ë°°ì•„ ìˆ˜', 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜']\n",
    "\n",
    "for col in skewed_cols:\n",
    "    X_train_encoded[col + '_log'] = log1p(X_train_encoded[col])\n",
    "    X_test_encoded[col + '_log'] = log1p(X_test_encoded[col])\n",
    "\n",
    "# 3ï¸âƒ£ 80% ì´ìƒ ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ ì œê±°\n",
    "missing_ratio = X_train_encoded.isnull().mean()\n",
    "high_missing_columns = missing_ratio[missing_ratio > 0.8].index.tolist()\n",
    "X_train_encoded.drop(columns=high_missing_columns, inplace=True)\n",
    "X_test_encoded.drop(columns=high_missing_columns, inplace=True)\n",
    "\n",
    "# 4ï¸âƒ£ Feature Engineering (íŠ¹ì„± ì¶”ê°€)\n",
    "X_train_encoded['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = X_train_encoded['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (X_train_encoded['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)\n",
    "X_test_encoded['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = X_test_encoded['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (X_test_encoded['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)\n",
    "\n",
    "X_train_encoded['ë°°ì•„_ì €ì¥_ë¹„ìœ¨'] = X_train_encoded['ì €ì¥ëœ ë°°ì•„ ìˆ˜'] / (X_train_encoded['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "X_test_encoded['ë°°ì•„_ì €ì¥_ë¹„ìœ¨'] = X_test_encoded['ì €ì¥ëœ ë°°ì•„ ìˆ˜'] / (X_test_encoded['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "\n",
    "X_train_encoded['ë‚œì_ë°°ì•„_ë¹„ìœ¨'] = X_train_encoded['ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜'] / (X_train_encoded['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "X_test_encoded['ë‚œì_ë°°ì•„_ë¹„ìœ¨'] = X_test_encoded['ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜'] / (X_test_encoded['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)\n",
    "\n",
    "\n",
    "# 5ï¸âƒ£ ì´ìƒì¹˜ ì²˜ë¦¬ (Clip ì ìš©)\n",
    "for col in ['ì´ ìƒì„± ë°°ì•„ ìˆ˜', 'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜', 'ì €ì¥ëœ ë°°ì•„ ìˆ˜']:\n",
    "    X_train_encoded[col] = X_train_encoded[col].clip(lower=1, upper=50)\n",
    "    X_test_encoded[col] = X_test_encoded[col].clip(lower=1, upper=50)\n",
    "\n",
    "# 6ï¸âƒ£ Feature Scaling ì œê±° (íŠ¸ë¦¬ ëª¨ë¸ì€ ë¶ˆí•„ìš”)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ìƒê´€ í–‰ë ¬ ê³„ì‚°\n",
    "corr_matrix = X_train_encoded.corr()\n",
    "\n",
    "# ë†’ì€ ìƒê´€ê´€ê³„(ì ˆëŒ€ê°’ 0.9 ì´ìƒ)ë¥¼ ê°€ì§€ëŠ” ë³€ìˆ˜ ì°¾ê¸°\n",
    "high_corr_features = set()\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            high_corr_features.add(colname)\n",
    "\n",
    "print(\"ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ëŠ” Feature:\", high_corr_features)\n",
    "\n",
    "# ì œê±°\n",
    "X_train_encoded.drop(columns=high_corr_features, inplace=True)\n",
    "X_test_encoded.drop(columns=high_corr_features, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optuna Hyperparameter Tuning:   0%|          | 0/50 [00:00<?, ?it/s][I 2025-02-03 02:50:35,854] A new study created in memory with name: no-name-51aafff9-5ef4-4328-9699-59e0bb9016dc\n",
      "[I 2025-02-03 02:51:16,783] Trial 0 finished with value: 0.7373527621262215 and parameters: {'n_estimators': 662, 'max_depth': 9, 'learning_rate': 0.018423208602250003, 'reg_lambda': 3.6293412499217794}. Best is trial 0 with value: 0.7373527621262215.\n",
      "Optuna Hyperparameter Tuning:   2%|â–         | 1/50 [00:40<33:25, 40.93s/it][I 2025-02-03 02:51:38,781] Trial 1 finished with value: 0.7373081160159602 and parameters: {'n_estimators': 298, 'max_depth': 10, 'learning_rate': 0.014541710478097434, 'reg_lambda': 5.205682481281475}. Best is trial 0 with value: 0.7373527621262215.\n",
      "Optuna Hyperparameter Tuning:   0%|          | 0/50 [02:49<?, ?it/s].79s/it]\n",
      "[I 2025-02-03 02:52:36,405] Trial 2 finished with value: 0.6956604172554173 and parameters: {'n_estimators': 825, 'max_depth': 12, 'learning_rate': 0.24263527713372918, 'reg_lambda': 7.695407587194057}. Best is trial 0 with value: 0.7373527621262215.\n",
      "Optuna Hyperparameter Tuning:   6%|â–Œ         | 3/50 [02:00<33:17, 42.50s/it][I 2025-02-03 02:52:47,304] Trial 3 finished with value: 0.7258675517118048 and parameters: {'n_estimators': 158, 'max_depth': 10, 'learning_rate': 0.26731323639471166, 'reg_lambda': 6.6960796733242764}. Best is trial 0 with value: 0.7373527621262215.\n",
      "Optuna Hyperparameter Tuning:   8%|â–Š         | 4/50 [02:11<23:01, 30.03s/it][I 2025-02-03 02:53:45,777] Trial 4 finished with value: 0.7374363282249528 and parameters: {'n_estimators': 954, 'max_depth': 9, 'learning_rate': 0.011904732122410352, 'reg_lambda': 3.173711081631305}. Best is trial 4 with value: 0.7374363282249528.\n",
      "Optuna Hyperparameter Tuning:  10%|â–ˆ         | 5/50 [03:09<30:12, 40.28s/it][I 2025-02-03 02:54:19,501] Trial 5 finished with value: 0.7356102500839661 and parameters: {'n_estimators': 613, 'max_depth': 8, 'learning_rate': 0.06231444745085109, 'reg_lambda': 9.69827217580896}. Best is trial 4 with value: 0.7374363282249528.\n",
      "Optuna Hyperparameter Tuning:  12%|â–ˆâ–        | 6/50 [03:43<27:54, 38.05s/it][I 2025-02-03 02:54:28,749] Trial 6 finished with value: 0.736977043706186 and parameters: {'n_estimators': 145, 'max_depth': 7, 'learning_rate': 0.014238750298852286, 'reg_lambda': 4.415268893290958}. Best is trial 4 with value: 0.7374363282249528.\n",
      "Optuna Hyperparameter Tuning:  14%|â–ˆâ–        | 7/50 [03:52<20:31, 28.64s/it][I 2025-02-03 02:55:28,607] Trial 7 finished with value: 0.7292995018064781 and parameters: {'n_estimators': 955, 'max_depth': 11, 'learning_rate': 0.043619762919894174, 'reg_lambda': 7.392510081179292}. Best is trial 4 with value: 0.7374363282249528.\n",
      "Optuna Hyperparameter Tuning:  16%|â–ˆâ–Œ        | 8/50 [04:52<27:00, 38.58s/it][I 2025-02-03 02:56:07,281] Trial 8 finished with value: 0.7341976402888435 and parameters: {'n_estimators': 696, 'max_depth': 8, 'learning_rate': 0.05567185296419221, 'reg_lambda': 1.9885363549026143}. Best is trial 4 with value: 0.7374363282249528.\n",
      "Optuna Hyperparameter Tuning:  18%|â–ˆâ–Š        | 9/50 [05:31<26:22, 38.61s/it][I 2025-02-03 02:56:26,398] Trial 9 finished with value: 0.737134034925693 and parameters: {'n_estimators': 422, 'max_depth': 4, 'learning_rate': 0.014304308253458103, 'reg_lambda': 7.411913568791763}. Best is trial 4 with value: 0.7374363282249528.\n",
      "Optuna Hyperparameter Tuning:  20%|â–ˆâ–ˆ        | 10/50 [05:50<21:43, 32.59s/it][I 2025-02-03 02:57:17,416] Trial 10 finished with value: 0.7390595202896701 and parameters: {'n_estimators': 988, 'max_depth': 6, 'learning_rate': 0.006399267862092527, 'reg_lambda': 1.0522386394689756}. Best is trial 10 with value: 0.7390595202896701.\n",
      "Optuna Hyperparameter Tuning:  22%|â–ˆâ–ˆâ–       | 11/50 [06:41<24:50, 38.23s/it][I 2025-02-03 02:58:08,775] Trial 11 finished with value: 0.7388189334085874 and parameters: {'n_estimators': 983, 'max_depth': 6, 'learning_rate': 0.005436213620910689, 'reg_lambda': 1.6961475263194616}. Best is trial 10 with value: 0.7390595202896701.\n",
      "Optuna Hyperparameter Tuning:  24%|â–ˆâ–ˆâ–       | 12/50 [07:32<26:44, 42.22s/it][I 2025-02-03 02:58:49,617] Trial 12 finished with value: 0.7378924671100184 and parameters: {'n_estimators': 839, 'max_depth': 5, 'learning_rate': 0.006251084211713756, 'reg_lambda': 1.040390499896182}. Best is trial 10 with value: 0.7390595202896701.\n",
      "Optuna Hyperparameter Tuning:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [08:13<25:46, 41.81s/it][I 2025-02-03 02:59:40,661] Trial 13 finished with value: 0.7386983408474395 and parameters: {'n_estimators': 986, 'max_depth': 6, 'learning_rate': 0.005044897853984609, 'reg_lambda': 1.0003733421064875}. Best is trial 10 with value: 0.7390595202896701.\n",
      "Optuna Hyperparameter Tuning:  28%|â–ˆâ–ˆâ–Š       | 14/50 [09:04<26:45, 44.60s/it][I 2025-02-03 03:00:22,690] Trial 14 finished with value: 0.739007593169888 and parameters: {'n_estimators': 811, 'max_depth': 6, 'learning_rate': 0.0075087480385859825, 'reg_lambda': 2.654756674391735}. Best is trial 10 with value: 0.7390595202896701.\n",
      "Optuna Hyperparameter Tuning:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [09:46<25:33, 43.82s/it][I 2025-02-03 03:00:59,084] Trial 15 finished with value: 0.7378571390842165 and parameters: {'n_estimators': 798, 'max_depth': 4, 'learning_rate': 0.11373408483804932, 'reg_lambda': 2.568378390273409}. Best is trial 10 with value: 0.7390595202896701.\n",
      "Optuna Hyperparameter Tuning:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [10:23<23:33, 41.59s/it][I 2025-02-03 03:01:25,267] Trial 16 finished with value: 0.7394503017196363 and parameters: {'n_estimators': 476, 'max_depth': 6, 'learning_rate': 0.02605809182175516, 'reg_lambda': 3.7025698387314208}. Best is trial 16 with value: 0.7394503017196363.\n",
      "Optuna Hyperparameter Tuning:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [10:49<20:19, 36.95s/it][I 2025-02-03 03:01:53,768] Trial 17 finished with value: 0.7390985678396094 and parameters: {'n_estimators': 465, 'max_depth': 7, 'learning_rate': 0.027557093176972036, 'reg_lambda': 4.33263452515897}. Best is trial 16 with value: 0.7394503017196363.\n",
      "Optuna Hyperparameter Tuning:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [11:17<18:21, 34.41s/it][I 2025-02-03 03:02:22,552] Trial 18 finished with value: 0.739128533962037 and parameters: {'n_estimators': 462, 'max_depth': 7, 'learning_rate': 0.024065763978704583, 'reg_lambda': 5.316577325268539}. Best is trial 16 with value: 0.7394503017196363.\n",
      "Optuna Hyperparameter Tuning:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [11:46<16:54, 32.72s/it][I 2025-02-03 03:02:48,623] Trial 19 finished with value: 0.7395692025087528 and parameters: {'n_estimators': 487, 'max_depth': 5, 'learning_rate': 0.026396128013431382, 'reg_lambda': 6.060303052762334}. Best is trial 19 with value: 0.7395692025087528.\n",
      "Optuna Hyperparameter Tuning:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [12:12<15:21, 30.73s/it][I 2025-02-03 03:03:05,095] Trial 20 finished with value: 0.7394007018462804 and parameters: {'n_estimators': 311, 'max_depth': 5, 'learning_rate': 0.0852655723168669, 'reg_lambda': 6.256822650417265}. Best is trial 19 with value: 0.7395692025087528.\n",
      "Optuna Hyperparameter Tuning:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [12:29<12:46, 26.45s/it][I 2025-02-03 03:03:21,880] Trial 21 finished with value: 0.7392064127668958 and parameters: {'n_estimators': 326, 'max_depth': 5, 'learning_rate': 0.09809574972255707, 'reg_lambda': 6.201514943533558}. Best is trial 19 with value: 0.7395692025087528.\n",
      "Optuna Hyperparameter Tuning:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [12:46<10:59, 23.55s/it][I 2025-02-03 03:03:37,916] Trial 22 finished with value: 0.7393925561335359 and parameters: {'n_estimators': 310, 'max_depth': 5, 'learning_rate': 0.031664964380225855, 'reg_lambda': 8.606396403277788}. Best is trial 19 with value: 0.7395692025087528.\n",
      "Optuna Hyperparameter Tuning:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [13:02<09:34, 21.29s/it][I 2025-02-03 03:04:03,455] Trial 23 finished with value: 0.7392274205336656 and parameters: {'n_estimators': 547, 'max_depth': 4, 'learning_rate': 0.09560019660561961, 'reg_lambda': 6.217922695487155}. Best is trial 19 with value: 0.7395692025087528.\n",
      "Optuna Hyperparameter Tuning:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [13:27<09:46, 22.57s/it][I 2025-02-03 03:04:14,896] Trial 24 finished with value: 0.738487708686621 and parameters: {'n_estimators': 224, 'max_depth': 5, 'learning_rate': 0.16033626948480853, 'reg_lambda': 4.302838426201321}. Best is trial 19 with value: 0.7395692025087528.\n",
      "Optuna Hyperparameter Tuning:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [13:39<08:00, 19.23s/it][I 2025-02-03 03:04:34,175] Trial 25 finished with value: 0.7394424280928595 and parameters: {'n_estimators': 393, 'max_depth': 5, 'learning_rate': 0.06475811839880417, 'reg_lambda': 5.932291079339549}. Best is trial 19 with value: 0.7395692025087528.\n",
      "Optuna Hyperparameter Tuning:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [13:58<07:41, 19.24s/it][I 2025-02-03 03:04:58,666] Trial 26 finished with value: 0.7397474813940252 and parameters: {'n_estimators': 543, 'max_depth': 4, 'learning_rate': 0.04141343625028309, 'reg_lambda': 5.0254908601228925}. Best is trial 26 with value: 0.7397474813940252.\n",
      "Optuna Hyperparameter Tuning:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [14:22<07:58, 20.82s/it][I 2025-02-03 03:05:24,098] Trial 27 finished with value: 0.7397750723377555 and parameters: {'n_estimators': 550, 'max_depth': 4, 'learning_rate': 0.04195471561862098, 'reg_lambda': 4.860607358122689}. Best is trial 27 with value: 0.7397750723377555.\n",
      "Optuna Hyperparameter Tuning:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [14:48<08:08, 22.20s/it][I 2025-02-03 03:05:49,376] Trial 28 finished with value: 0.7397517137686149 and parameters: {'n_estimators': 555, 'max_depth': 4, 'learning_rate': 0.0398157705548641, 'reg_lambda': 4.905905774148797}. Best is trial 27 with value: 0.7397750723377555.\n",
      "Optuna Hyperparameter Tuning:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [15:13<08:05, 23.13s/it][I 2025-02-03 03:06:19,006] Trial 29 finished with value: 0.7397475716075264 and parameters: {'n_estimators': 663, 'max_depth': 4, 'learning_rate': 0.03857372695544873, 'reg_lambda': 4.847393111692977}. Best is trial 27 with value: 0.7397750723377555.\n",
      "Optuna Hyperparameter Tuning:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [15:43<08:21, 25.08s/it][I 2025-02-03 03:06:49,492] Trial 30 finished with value: 0.7393792307759928 and parameters: {'n_estimators': 679, 'max_depth': 4, 'learning_rate': 0.01945837141338953, 'reg_lambda': 3.5463648187210826}. Best is trial 27 with value: 0.7397750723377555.\n",
      "Optuna Hyperparameter Tuning:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [16:13<08:27, 26.70s/it][I 2025-02-03 03:07:16,037] Trial 31 finished with value: 0.7398304054054625 and parameters: {'n_estimators': 585, 'max_depth': 4, 'learning_rate': 0.040314325768186714, 'reg_lambda': 4.9869088471461165}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [16:40<07:59, 26.65s/it][I 2025-02-03 03:07:46,709] Trial 32 finished with value: 0.7396976404362081 and parameters: {'n_estimators': 630, 'max_depth': 4, 'learning_rate': 0.05015036536175722, 'reg_lambda': 4.892905358152067}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [17:10<07:53, 27.86s/it][I 2025-02-03 03:08:21,055] Trial 33 finished with value: 0.7397689374431327 and parameters: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.03532372771942896, 'reg_lambda': 5.535694136373442}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [17:45<07:56, 29.80s/it][I 2025-02-03 03:08:58,626] Trial 34 finished with value: 0.7396956204335798 and parameters: {'n_estimators': 740, 'max_depth': 4, 'learning_rate': 0.0339200691305885, 'reg_lambda': 5.584111140419393}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [18:22<08:02, 32.13s/it][I 2025-02-03 03:09:41,634] Trial 35 finished with value: 0.7334921846956759 and parameters: {'n_estimators': 585, 'max_depth': 12, 'learning_rate': 0.018938919764636745, 'reg_lambda': 6.937306349424977}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [19:05<08:15, 35.40s/it][I 2025-02-03 03:10:17,807] Trial 36 finished with value: 0.7295805231514139 and parameters: {'n_estimators': 573, 'max_depth': 10, 'learning_rate': 0.07554650570693396, 'reg_lambda': 4.137198329416116}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [19:41<07:43, 35.63s/it][I 2025-02-03 03:10:42,954] Trial 37 finished with value: 0.7394995802132596 and parameters: {'n_estimators': 520, 'max_depth': 5, 'learning_rate': 0.04858819057188847, 'reg_lambda': 5.550692695325995}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [20:07<06:29, 32.48s/it][I 2025-02-03 03:11:28,835] Trial 38 finished with value: 0.737902351818099 and parameters: {'n_estimators': 736, 'max_depth': 9, 'learning_rate': 0.010043041243008316, 'reg_lambda': 3.7674685070252827}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [20:52<06:41, 36.50s/it][I 2025-02-03 03:12:08,900] Trial 39 finished with value: 0.7329710838467653 and parameters: {'n_estimators': 627, 'max_depth': 11, 'learning_rate': 0.034366830115278225, 'reg_lambda': 6.606138969554486}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [21:33<06:15, 37.57s/it][I 2025-02-03 03:12:29,128] Trial 40 finished with value: 0.734268017337655 and parameters: {'n_estimators': 381, 'max_depth': 7, 'learning_rate': 0.1375798785361555, 'reg_lambda': 4.710039711033981}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [21:53<04:51, 32.37s/it][I 2025-02-03 03:12:58,537] Trial 41 finished with value: 0.7397313562816211 and parameters: {'n_estimators': 655, 'max_depth': 4, 'learning_rate': 0.040378920910559175, 'reg_lambda': 4.709149344950596}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [22:22<04:11, 31.48s/it][I 2025-02-03 03:13:25,313] Trial 42 finished with value: 0.7395932873361339 and parameters: {'n_estimators': 596, 'max_depth': 4, 'learning_rate': 0.061775439890587716, 'reg_lambda': 5.5782158303255125}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [22:49<03:30, 30.07s/it][I 2025-02-03 03:13:57,572] Trial 43 finished with value: 0.7395656104923944 and parameters: {'n_estimators': 717, 'max_depth': 4, 'learning_rate': 0.021205700683947875, 'reg_lambda': 5.333899134326435}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [23:21<03:04, 30.73s/it][I 2025-02-03 03:14:22,074] Trial 44 finished with value: 0.7396031069314841 and parameters: {'n_estimators': 503, 'max_depth': 5, 'learning_rate': 0.03403472839539021, 'reg_lambda': 3.1316902711266628}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [23:46<02:24, 28.86s/it][I 2025-02-03 03:14:51,841] Trial 45 finished with value: 0.7396500323870029 and parameters: {'n_estimators': 669, 'max_depth': 4, 'learning_rate': 0.04858796324900133, 'reg_lambda': 4.716884768392863}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [24:15<01:56, 29.13s/it][I 2025-02-03 03:15:35,702] Trial 46 finished with value: 0.7394325492962424 and parameters: {'n_estimators': 862, 'max_depth': 6, 'learning_rate': 0.01599003900967131, 'reg_lambda': 4.011470304983046}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [24:59<01:40, 33.55s/it][I 2025-02-03 03:16:11,004] Trial 47 finished with value: 0.7391856964923269 and parameters: {'n_estimators': 762, 'max_depth': 4, 'learning_rate': 0.06874686276056316, 'reg_lambda': 3.2753112712352626}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [25:35<01:08, 34.08s/it][I 2025-02-03 03:16:46,774] Trial 48 finished with value: 0.7389649924714939 and parameters: {'n_estimators': 635, 'max_depth': 5, 'learning_rate': 0.05772981491690438, 'reg_lambda': 5.1087055769267}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [26:10<00:34, 34.58s/it][I 2025-02-03 03:17:10,296] Trial 49 finished with value: 0.7391730311726076 and parameters: {'n_estimators': 424, 'max_depth': 6, 'learning_rate': 0.04384291517192496, 'reg_lambda': 7.101891884259034}. Best is trial 31 with value: 0.7398304054054625.\n",
      "Optuna Hyperparameter Tuning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [26:34<00:00, 31.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Optuna ìµœì í™” ì™„ë£Œ! ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {'n_estimators': 585, 'max_depth': 4, 'learning_rate': 0.040314325768186714, 'reg_lambda': 4.9869088471461165}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: ROC-AUC = 0.7378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: ROC-AUC = 0.7427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: ROC-AUC = 0.7399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: ROC-AUC = 0.7376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross Validation Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20<00:00,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: ROC-AUC = 0.7411\n",
      "\n",
      "âœ… 5-Fold ROC-AUC ì ìˆ˜ í‰ê· : 0.7398\n",
      "ê° Fold ì ìˆ˜: [0.737842502513753, 0.7427190621099498, 0.7398947613739844, 0.737643518351006, 0.7410521826786194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from tqdm import tqdm\n",
    "\n",
    "# Optuna ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ëŠ” tqdm ì½œë°± í•¨ìˆ˜\n",
    "class TQDMCallback:\n",
    "    def __init__(self, total):\n",
    "        self.pbar = tqdm(total=total, desc=\"Optuna Hyperparameter Tuning\", position=0, leave=True)\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        self.pbar.update(1)\n",
    "\n",
    "    def close(self):\n",
    "        self.pbar.close()\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Optuna)\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 10.0),\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in cv.split(X_train_encoded, y):\n",
    "        X_train_fold, X_val_fold = X_train_encoded.iloc[train_idx], X_train_encoded.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model.fit(\n",
    "            X_train_fold,\n",
    "            y_train_fold,\n",
    "            eval_set=[(X_val_fold, y_val_fold)],\n",
    "            verbose=False\n",
    "        )\n",
    "        y_val_pred = model.predict_proba(X_val_fold)[:, 1]\n",
    "        \n",
    "        auc_score = roc_auc_score(y_val_fold, y_val_pred)\n",
    "        cv_scores.append(auc_score)\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# Optuna ìµœì í™” ì‹¤í–‰ (ì‹œë„ íšŸìˆ˜: 50ë²ˆ, tqdm ì¶”ê°€)\n",
    "n_trials = 50\n",
    "tqdm_callback = TQDMCallback(total=n_trials)\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=n_trials, callbacks=[tqdm_callback])\n",
    "tqdm_callback.close()\n",
    "\n",
    "# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
    "best_params = study.best_params\n",
    "print(f\"âœ… Optuna ìµœì í™” ì™„ë£Œ! ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {best_params}\")\n",
    "\n",
    "# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©\n",
    "# (XGBoostëŠ” random_stateë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë‹¤ì‹œ ì§€ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.)\n",
    "model = xgb.XGBClassifier(**best_params, random_state=42)\n",
    "\n",
    "# êµì°¨ ê²€ì¦ ì„¤ì • (5-Fold)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ì§„í–‰ë„ í‘œì‹œë¥¼ ìœ„í•œ tqdm ì ìš©\n",
    "cv_scores = []\n",
    "for fold, (train_idx, val_idx) in enumerate(tqdm(cv.split(X_train_encoded, y), desc=\"Cross Validation Progress\", total=5)):\n",
    "    X_train_fold, X_val_fold = X_train_encoded.iloc[train_idx], X_train_encoded.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_fold,\n",
    "        y_train_fold,\n",
    "        eval_set=[(X_val_fold, y_val_fold)],\n",
    "        verbose=False\n",
    "    )\n",
    "    y_val_pred = model.predict_proba(X_val_fold)[:, 1]\n",
    "    \n",
    "    auc_score = roc_auc_score(y_val_fold, y_val_pred)\n",
    "    cv_scores.append(auc_score)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: ROC-AUC = {auc_score:.4f}\")\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"\\nâœ… 5-Fold ROC-AUC ì ìˆ˜ í‰ê· : {np.mean(cv_scores):.4f}\")\n",
    "print(f\"ê° Fold ì ìˆ˜: {cv_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train_encoded, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict_proba(X_test_encoded)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "sample_submission['probability'] = pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
